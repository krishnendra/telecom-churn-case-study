{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_missing_values(df,fig_x,fig_y):\n",
    "    # check null value\n",
    "    percent_missing = df.isnull().sum() * 100 / len(df)\n",
    "    missing_values_df = pd.DataFrame({'column_name': df.columns, 'percent_missing': percent_missing})\n",
    "    missing_values_df.sort_values('percent_missing', inplace=True, ascending=False)\n",
    "    missing_values_df = missing_values_df[missing_values_df.percent_missing > 0]\n",
    "    if len(missing_values_df) > 0:\n",
    "        plt.figure(figsize=(fig_x,fig_y))\n",
    "        sns.barplot(x = 'percent_missing',y = 'column_name',data = missing_values_df)\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"No data available\")    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = pd.read_csv(\"sample.csv\")\n",
    "df_sample.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the training set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns',230)\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "df_train = pd.read_csv(\"train.csv\")\n",
    "df_train.head(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_test = pd.read_csv(\"test.csv\")\n",
    "df_test.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_train.columns:\n",
    "    if col not in df_test.columns:\n",
    "        print(col)\n",
    "# the churn probability is not in test data      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check null value\n",
    "plot_missing_values(df_train,25,50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to impute values \n",
    "def impute_columns (df, imputes=False, mising_columns=False):\n",
    "    # Function impute the nan with 0\n",
    "    # argument: colList, list of columns for which nan is to be replaced with 0\n",
    "    if imputes:\n",
    "        for col in [impute + suffix for suffix in ['_6','_7','_8'] for impute in imputes]:\n",
    "            df[col].fillna(0, inplace=True)\n",
    "    else:    \n",
    "        for col in mising_columns:\n",
    "            df[col].fillna(0, inplace=True)\n",
    "\n",
    "# Business Related Columns , we need to impute these , rather than drop the columns \n",
    "biz_columns = ['arpu_3g','count_rech_2g','night_pck_user','arpu_2g','total_rech_data','av_rech_amt_data','max_rech_data','count_rech_3g','fb_user']\n",
    "impute_columns(df_train,biz_columns)\n",
    "impute_columns(df_test,biz_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check null value\n",
    "plot_missing_values(df_train,25,50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute the stats columns \n",
    "interesting_columns = ['loc_og_t2c_mou','std_ic_t2t_mou','loc_og_t2t_mou','loc_og_t2m_mou',\n",
    "                       'std_ic_t2f_mou','loc_og_t2f_mou','std_ic_t2m_mou','loc_og_mou',\n",
    "                       'std_og_t2t_mou','std_og_t2m_mou','std_og_t2f_mou','std_ic_t2o_mou',\n",
    "                       'std_og_t2c_mou','std_og_mou','loc_ic_mou','isd_og_mou',\n",
    "                       'spl_og_mou','og_others','loc_ic_t2f_mou','loc_ic_t2m_mou',\n",
    "                       'roam_og_mou','loc_ic_t2t_mou','spl_ic_mou','ic_others',\n",
    "                       'roam_ic_mou','onnet_mou','isd_ic_mou','offnet_mou','std_ic_mou']\n",
    "\n",
    "impute_columns(df_train,imputes=interesting_columns)\n",
    "impute_columns(df_test,imputes=interesting_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check null value\n",
    "plot_missing_values(df_train,5,5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date column treatment\n",
    "last_day_data_columns = ['date_of_last_rech_data_6','date_of_last_rech_data_7','date_of_last_rech_data_8']\n",
    "df_train[df_train['date_of_last_rech_data_6'].isnull()]['date_of_last_rech_data_6'] = '6/30/2014'\n",
    "df_train[df_train['date_of_last_rech_data_7'].isnull()]['date_of_last_rech_data_7'] = '7/31/2014'\n",
    "df_train[df_train['date_of_last_rech_data_8'].isnull()]['date_of_last_rech_data_8'] = '8/31/2014'\n",
    "\n",
    "df_test[df_test['date_of_last_rech_data_6'].isnull()]['date_of_last_rech_data_6'] = '6/30/2014'\n",
    "df_test[df_test['date_of_last_rech_data_7'].isnull()]['date_of_last_rech_data_7'] = '7/31/2014'\n",
    "df_test[df_test['date_of_last_rech_data_8'].isnull()]['date_of_last_rech_data_8'] = '8/31/2014'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check values for uniqueness\n",
    "unique_value_columns = ['last_date_of_month_8','loc_og_t2o_mou','std_og_t2o_mou','loc_ic_t2o_mou','last_date_of_month_7']\n",
    "for col in unique_value_columns:\n",
    "    print(df_train[col].unique())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in unique_value_columns:\n",
    "    print(df_test[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in unique_value_columns:\n",
    "   df_train.fillna(df_train[col].mode()[0],inplace=True)\n",
    "   df_test.fillna(df_test[col].mode()[0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_missing_values(df_train,5,5)\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_missing_values(df_test,5,5)\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns with Single Values \n",
    "single_valued_columns = df_train.columns[df_train.nunique() <= 1]\n",
    "single_valued_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_value_drop_columns = ['std_og_t2c_mou_6','std_og_t2c_mou_7','std_og_t2c_mou_8',\n",
    "                             'std_ic_t2o_mou_6','std_ic_t2o_mou_7','std_ic_t2o_mou_8','circle_id']\n",
    "df_train.drop(single_value_drop_columns,axis=1,inplace=True)\n",
    "df_test.drop(single_value_drop_columns,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_train.id.value_counts())\n",
    "#remove id\n",
    "df_train.drop(['id'],axis=1,inplace=True)\n",
    "df_test.drop(['id'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.reset_index(inplace=True,drop=True)\n",
    "df_train.shape\n",
    "df_test.reset_index(inplace=True,drop=True)\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date Columns\n",
    "dates = list(df_train.filter(regex='date').columns)\n",
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for date_column in dates:\n",
    "    df_train[date_column] = pd.to_datetime(df_train[date_column], format='%m/%d/%Y')\n",
    "    df_test[date_column] = pd.to_datetime(df_test[date_column], format='%m/%d/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()\n",
    "\n",
    "for dtype_col in df_train.columns:\n",
    "    if df_train[dtype_col].dtype == object:\n",
    "        print(dtype_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc_ic_t2o_mou.unique()\n",
    "# drop these columns \n",
    "object_columns = ['loc_og_t2o_mou','std_og_t2o_mou','loc_ic_t2o_mou']\n",
    "df_train.drop(object_columns,axis=1,inplace=True)\n",
    "df_test.drop(object_columns,axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unconventional_columns = list(df_train.filter(regex='vbc').columns)\n",
    "unconventional_columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename to conventional column names\n",
    "df_train.rename(columns={'aug_vbc_3g' : 'vbc_3g_8', 'jul_vbc_3g' : 'vbc_3g_7', 'jun_vbc_3g' : 'vbc_3g_6'}, inplace=True)\n",
    "df_test.rename(columns={'aug_vbc_3g' : 'vbc_3g_8', 'jul_vbc_3g' : 'vbc_3g_7', 'jun_vbc_3g' : 'vbc_3g_6'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_train.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Skewness\n",
    "for col_name in df_train.columns:\n",
    "    if (len(df_train[col_name].unique()) <= 8):\n",
    "        print(df_train[col_name].value_counts())\n",
    "        print(f\"\\n{35 * '-'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_2 = df_train.copy()\n",
    "#Find Highly correlated data and drop Highly Correlated Columns\n",
    "cor = df_train_2.corr()\n",
    "cor.loc[:,:] = np.tril(cor, k=-1)\n",
    "cor = cor.stack()\n",
    "cor[(cor > 0.60) | (cor < -0.60)].sort_values(ascending=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "df_train.drop(dates,axis=1,inplace=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3 = df_train_2.select_dtypes(exclude=['datetime64'])\n",
    "df_3.info()\n",
    "\n",
    "X = df_3.drop(['churn_probability'], axis=1)\n",
    "y = df_3['churn_probability']\n",
    "\n",
    "scaler = StandardScaler().fit(X)\n",
    "X = scaler.transform(X)\n",
    "\n",
    "df_4 = df_test.select_dtypes(exclude=['datetime64'])\n",
    "X1_test = df_4.copy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, train_size=0.7, random_state=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "sm = SMOTE()\n",
    "X_tr,y_tr = sm.fit_resample(X_train,y_train)\n",
    "print(X_tr.shape)\n",
    "print(y_tr.shape)\n",
    "\n",
    "#Improting the PCA module\n",
    "pca = PCA(random_state=100)\n",
    "\n",
    "#Doing the PCA on the train data\n",
    "pca.fit(X_tr)\n",
    "\n",
    "X_tr_pca = pca.fit_transform(X_tr)\n",
    "print(X_tr_pca.shape)\n",
    "\n",
    "X_test_pca = pca.transform(X_test)\n",
    "print(X_test_pca.shape)\n",
    "\n",
    "X_tr_pca_1 = X_tr_pca.copy()\n",
    "X_test_pca_1 = X_test_pca.copy()\n",
    "\n",
    "X_tr_pca_2 = X_tr_pca.copy()\n",
    "X_test_pca_2 = X_test_pca.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr_pca = LogisticRegression(max_iter=500)\n",
    "lr_pca.fit(X_tr_pca, y_tr)\n",
    "\n",
    "# Predicted probabilities\n",
    "y_pred = lr_pca.predict(X_test_pca)\n",
    "\n",
    "# Converting y_pred to a dataframe which is an array\n",
    "y_pred_df = pd.DataFrame(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "conf_mat = confusion_matrix(y_test,y_pred)\n",
    "print(conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = conf_mat[1,1]\n",
    "# Substituting the value of true negatives\n",
    "TN = conf_mat[0,0]\n",
    "# Substituting the value of false positives\n",
    "FP = conf_mat[0,1] \n",
    "# Substituting the value of false negatives\n",
    "FN = conf_mat[1,0]\n",
    "\n",
    "# Calculating the sensitivity\n",
    "sens_log_pca=TP/(TP+FN)\n",
    "\n",
    "# Calculating the specificity\n",
    "spec_log_pca=TN/(TN+FP)\n",
    "\n",
    "print(\"Sensitivity:\" ,sens_log_pca)\n",
    "print(\"Specificity:\" ,spec_log_pca)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Logistic Regression accuracy with PCA: \",accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_5=df_3.copy()\n",
    "df_5.drop('churn_probability', axis=1,inplace=True)\n",
    "col = list(df_5.columns)\n",
    "df_pca = pd.DataFrame({'PCA1':pca.components_[0],'PCA2':pca.components_[1], 'PCA3':pca.components_[2],'Feature':col})\n",
    "df_pca.head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig = plt.figure(figsize = (12,8))\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.cumsum(np.round(pca.explained_variance_ratio_, decimals=4)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_54 = PCA(n_components=54)\n",
    "\n",
    "df_tr_pca_54 = pca_54.fit_transform(X_tr)\n",
    "print(df_tr_pca_54.shape)\n",
    "\n",
    "df_test_pca_54 = pca_54.transform(X_test)\n",
    "print(df_test_pca_54.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's run the model using the selected variables\n",
    "lr_pca1 = LogisticRegression(max_iter=500)\n",
    "lr_pca1.fit(df_tr_pca_54, y_tr)\n",
    "\n",
    "# Predicted probabilities\n",
    "y_pred54 = lr_pca1.predict(df_test_pca_54)\n",
    "\n",
    "# Converting y_pred to a dataframe which is an array\n",
    "df_y_pred = pd.DataFrame(y_pred54)\n",
    "\n",
    "conf_matrices = confusion_matrix(y_test,y_pred54)\n",
    "\n",
    "# check sensitivity and specificity\n",
    "\n",
    "# Substituting the value of true positive\n",
    "TP = conf_matrices[1,1]\n",
    "# Substituting the value of true negatives\n",
    "TN = conf_matrices[0,0]\n",
    "# Substituting the value of false positives\n",
    "FP = conf_matrices[0,1] \n",
    "# Substituting the value of false negatives\n",
    "FN = conf_matrices[1,0]\n",
    "\n",
    "# Calculating the sensitivity\n",
    "sens_log_pca=TP/(TP+FN)\n",
    "\n",
    "# Calculating the specificity\n",
    "spec_log_pca=TN/(TN+FP)\n",
    "\n",
    "print(\"Sensitivity:\" ,sens_log_pca)\n",
    "print(\"Specificity:\" ,spec_log_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Logistic Regression accuracy with PCA: \",accuracy_score(y_test,y_pred54))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuning hyper parameters \n",
    "# Importing libraries for cross validation\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Creating KFold object with 5 splits\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=4)\n",
    "\n",
    "# Specify params\n",
    "params = {\"C\": [0.01, 0.1, 1, 10, 100, 1000]}\n",
    "\n",
    "# Specifing score as recall as we are more focused on acheiving the higher sensitivity than the accuracy\n",
    "model_cv = GridSearchCV(estimator = LogisticRegression(),\n",
    "                        param_grid = params, \n",
    "                        scoring= 'recall', \n",
    "                        cv = folds, \n",
    "                        verbose = 1,\n",
    "                        return_train_score=True) \n",
    "\n",
    "# Fit the model\n",
    "model_cv.fit(X_tr_pca_1, y_tr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results of grid search CV\n",
    "cv_results = pd.DataFrame(model_cv.cv_results_)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(cv_results['param_C'], cv_results['mean_test_score'])\n",
    "plt.plot(cv_results['param_C'], cv_results['mean_train_score'])\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('sensitivity')\n",
    "plt.legend(['test result', 'train result'], loc='upper left')\n",
    "plt.xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best score with best C\n",
    "best_score = model_cv.best_score_\n",
    "best_C = model_cv.best_params_['C']\n",
    "\n",
    "print(\" The highest test sensitivity is {0} at C = {1}\".format(best_score, best_C))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic regression with optimal C\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Instantiate the model with best C\n",
    "logistic_pca = LogisticRegression(C=best_C)\n",
    "\n",
    "# Fit the model on the train set\n",
    "log_pca_model = logistic_pca.fit(X_tr_pca_1, y_tr)\n",
    "\n",
    "# Predictions on the train set\n",
    "y_train_pred = log_pca_model.predict(X_tr_pca_1)\n",
    "\n",
    "# Confusion matrix\n",
    "confusion = metrics.confusion_matrix(y_tr, y_train_pred)\n",
    "print(confusion)\n",
    "\n",
    "TP = confusion[1,1] # true positive \n",
    "TN = confusion[0,0] # true negatives\n",
    "FP = confusion[0,1] # false positives\n",
    "FN = confusion[1,0] # false negatives\n",
    "\n",
    "# Accuracy\n",
    "print(\"Accuracy:-\",metrics.accuracy_score(y_tr, y_train_pred))\n",
    "\n",
    "# Sensitivity\n",
    "print(\"Sensitivity:-\",TP / float(TP+FN))\n",
    "\n",
    "# Specificity\n",
    "print(\"Specificity:-\", TN / float(TN+FP))\n",
    "\n",
    "# Prediction on the test set\n",
    "y_test_pred = log_pca_model.predict(X_test_pca)\n",
    "\n",
    "# Confusion matrix\n",
    "confusion = metrics.confusion_matrix(y_test, y_test_pred)\n",
    "print(confusion)\n",
    "\n",
    "TP = confusion[1,1] # true positive \n",
    "TN = confusion[0,0] # true negatives\n",
    "FP = confusion[0,1] # false positives\n",
    "FN = confusion[1,0] # false negatives\n",
    "\n",
    "# Accuracy\n",
    "print(\"Accuracy:-\",metrics.accuracy_score(y_test, y_test_pred))\n",
    "\n",
    "# Sensitivity\n",
    "print(\"Sensitivity:-\",TP / float(TP+FN))\n",
    "\n",
    "# Specificity\n",
    "print(\"Specificity:-\", TN / float(TN+FP))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# random forest - the class weight is used to handle class imbalance - it adjusts the cost function\n",
    "forest = RandomForestClassifier(class_weight={0:0.1, 1: 0.9}, n_jobs = 500)\n",
    "\n",
    "# hyperparameter space\n",
    "params = {\"criterion\": ['gini', 'entropy'], \"max_features\": ['sqrt', 0.4]}\n",
    "\n",
    "# create 5 folds\n",
    "folds = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 4)\n",
    "\n",
    "# create gridsearch object\n",
    "model = GridSearchCV(estimator=forest, cv=folds, param_grid=params, scoring='roc_auc', n_jobs=500, verbose=1)\n",
    "\n",
    "\n",
    "# fit model\n",
    "model.fit(X_tr_pca_2, y_tr)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iiitb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
